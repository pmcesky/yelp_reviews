{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daibaiyang/.conda/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **General Settings**\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load Yelp user review dataset\n",
    "\n",
    "df = pd.read_csv('./yelp_review_first_130K_with_sentiment.csv')\n",
    "\n",
    "# **Split Dataset into Train/Validation/Test**\n",
    "# Train 100K, Valid 10K, Test 20K\n",
    "\n",
    "train_texts = df.iloc[:100000]['text'].values\n",
    "train_labels = df.iloc[:100000]['sentiment'].values\n",
    "\n",
    "valid_texts = df.iloc[100000:110000]['text'].values\n",
    "valid_labels = df.iloc[100000:110000]['sentiment'].values\n",
    "\n",
    "test_texts = df.iloc[110000:]['text'].values\n",
    "test_labels = df.iloc[110000:]['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 73058\n"
     ]
    }
   ],
   "source": [
    "# 2. find unique tokens (words)\n",
    "token_counts = Counter()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = text.split()\n",
    "    return tokenized\n",
    "\n",
    "for line in train_texts:\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print('Vocab-size:', len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. encoding each unique token into integers\n",
    "\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x:x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "vocab = vocab(ordered_dict)\n",
    "vocab.insert_token('<pad>', 0)\n",
    "vocab.insert_token('<unk>', 1)\n",
    "vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 10, 60, 2203]\n"
     ]
    }
   ],
   "source": [
    "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Yelp Dataset\n",
    "\n",
    "class YelpDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        \"\"\"\n",
    "        'texts' here should be a list/array of texts, labels here should be a list/array of labels.\n",
    "        \"\"\"\n",
    "        self.reviews = texts # sentiments\n",
    "        self.labels = labels # labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.reviews[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.a: define functions for transformation\n",
    "\n",
    "# to transform each review in the dataset\n",
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.b: wrap the encode and transformation function\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _text, _label in batch:\n",
    "        label_list.append(_label)\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.float) # label\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "    return padded_text_list.to(DEVICE), label_list.to(DEVICE), lengths.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset, valid_dataset, and test_dataset\n",
    "train_dataset = YelpDataset(train_texts, train_labels)\n",
    "valid_dataset = YelpDataset(valid_texts, valid_labels)\n",
    "test_dataset = YelpDataset(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   18,    10,  2969,     5,   583,   327,     3,     2,    29,    10,\n",
      "            88,    84,     2, 17551,    21,    45,     2,   352,    10,   144,\n",
      "            42,     2,   368,     4,    92,    23,   177,     8,    26,    60,\n",
      "           327,    98,    45,    19,    63,   161,     6,    56,   104,   137,\n",
      "           369,     2,   355,    12,     2,   547,  1996,   528,   149,   165,\n",
      "            48,    45,     8,    26,    27,     5,   299,  2064,    48,     2,\n",
      "            29,    10,    63,    35,    21,   373,    27,   198,     5,   299,\n",
      "           127,    12,    13,  1087,    21,    45,    19,    71,   668,   247,\n",
      "             3,    47,    25,     6,    56,    98,     8,     2,   695,    31,\n",
      "            33,   383,     2,   236,   552,     3,     2,    46,    10,    33,\n",
      "            38,    83,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   47,   111,     6,   738,    70,  2019,     5,   296,  3365,    10,\n",
      "          1638,    30,     4,   724,   420,    42,   510,    19,    55,    74,\n",
      "           738,   142,  6640,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    4, 28875,     5,   709,    39,    15,   113,    24,  6340,    29,\n",
      "            12,   133,   596,    69,    24,    94,  1239,    29,    49,  8162,\n",
      "           734,  1464,     3,    30,    22,  1077,    14,    99,   150,   290,\n",
      "             3,   150,   789,     3,   669,    15,     7,  2749,     9,    29,\n",
      "            69,     7,   669,    80,     8,     3,   505,  2674,  7280,     9,\n",
      "             2,    29,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   18,    32,     7,    37,   307,    11,     5,  1579,   141,     3,\n",
      "             8,    26,    73,  1920,     2,    29,    10,    33,     2,   127,\n",
      "             7,     5,   195,   209,    21,    27,    91,   222,     2,   455,\n",
      "           220,    23,     2,  2747,    21,   621,     2,   508,     9,    18,\n",
      "            32,     8,   407,  1466,    39,    26,   126,   455,    40,   156,\n",
      "             2,   324,    16,  4517,   302,    39,    31,     5,   166,   371,\n",
      "            13,  1989,     3,     4,   460,   324,     4,   116,    23,   646,\n",
      "          1170,    38,   136,     4,     7,   402,     6,   776,    40,     2,\n",
      "          3326,    51,     2,   521,     2,   584,   945,    10,    33,    72,\n",
      "            24,    77,  3714,     4,    96,     2,  7536,    65,    10,   189,\n",
      "            13,   187,   569,   290,     9,    40,    48,     8,     7,   108,\n",
      "            13,   110,    48,   168,   416,     8,     3,     4,    62,   102,\n",
      "            36,   637,     8,   123,    13,  1989,    24,    53,   378,    65,\n",
      "            28,  2018,    38,   553,    33,   141,    42,    22,     2,  2993]],\n",
      "       device='cuda:0')\n",
      "tensor([1., 0., 1., 1.], device='cuda:0')\n",
      "tensor([102,  23,  52, 140], device='cuda:0')\n",
      "torch.Size([4, 140])\n"
     ]
    }
   ],
   "source": [
    "# take a small batch\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "# check if text is padded to same lengths\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print(text_batch)\n",
    "print(label_batch)\n",
    "print(length_batch)\n",
    "print(text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataloaders for train, valid, and test\n",
    "batch_size = BATCH_SIZE\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3792,  0.4689,  0.7525],\n",
      "         [-0.6422, -0.8128,  0.1794],\n",
      "         [ 0.4324, -1.4235, -2.1338],\n",
      "         [ 1.0524, -0.3885, -0.9343]],\n",
      "\n",
      "        [[ 0.4324, -1.4235, -2.1338],\n",
      "         [ 1.8951,  0.4954,  0.2692],\n",
      "         [-0.6422, -0.8128,  0.1794],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## embedding layers for sentence encoding\n",
    "# an example\n",
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=3, padding_idx=0)\n",
    "# num_embedding corresponds to the unique integer values that the model will receive as input (n+2, 2 includes 'pad' and 'unk')\n",
    "# embedding_dim is the size of embedding features\n",
    "\n",
    "# a batch of 2 samples of 4 indices each\n",
    "text_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]])\n",
    "print(embedding(text_encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build an RNN model for sentiment analysis task\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size,fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1,:,:]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(73060, 20, padding_idx=0)\n",
       "  (rnn): LSTM(20, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "torch.manual_seed(0)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size)\n",
    "model = model.to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train function\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
    " \n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/0100 | Accuracy: 0.7858 | Val_accuracy: 0.7899 | Time elapsed: 1.09 min\n",
      "Epoch: 0002/0100 | Accuracy: 0.7912 | Val_accuracy: 0.8116 | Time elapsed: 2.04 min\n",
      "Epoch: 0003/0100 | Accuracy: 0.8741 | Val_accuracy: 0.9014 | Time elapsed: 2.98 min\n",
      "Epoch: 0004/0100 | Accuracy: 0.9195 | Val_accuracy: 0.9279 | Time elapsed: 3.94 min\n",
      "Epoch: 0005/0100 | Accuracy: 0.9357 | Val_accuracy: 0.9390 | Time elapsed: 4.90 min\n",
      "Epoch: 0006/0100 | Accuracy: 0.9451 | Val_accuracy: 0.9458 | Time elapsed: 5.87 min\n",
      "Epoch: 0007/0100 | Accuracy: 0.9510 | Val_accuracy: 0.9530 | Time elapsed: 6.83 min\n",
      "Epoch: 0008/0100 | Accuracy: 0.9563 | Val_accuracy: 0.9564 | Time elapsed: 7.83 min\n",
      "Epoch: 0009/0100 | Accuracy: 0.9605 | Val_accuracy: 0.9614 | Time elapsed: 8.80 min\n",
      "Epoch: 0010/0100 | Accuracy: 0.9631 | Val_accuracy: 0.9628 | Time elapsed: 9.75 min\n",
      "Test_accuracy: 0.9473\n",
      "Epoch: 0011/0100 | Accuracy: 0.9661 | Val_accuracy: 0.9665 | Time elapsed: 10.86 min\n",
      "Epoch: 0012/0100 | Accuracy: 0.9694 | Val_accuracy: 0.9703 | Time elapsed: 11.83 min\n",
      "Epoch: 0013/0100 | Accuracy: 0.9705 | Val_accuracy: 0.9700 | Time elapsed: 12.79 min\n",
      "Epoch: 0014/0100 | Accuracy: 0.9737 | Val_accuracy: 0.9721 | Time elapsed: 13.77 min\n",
      "Epoch: 0015/0100 | Accuracy: 0.9756 | Val_accuracy: 0.9751 | Time elapsed: 14.75 min\n",
      "Epoch: 0016/0100 | Accuracy: 0.9777 | Val_accuracy: 0.9766 | Time elapsed: 15.76 min\n",
      "Epoch: 0017/0100 | Accuracy: 0.9800 | Val_accuracy: 0.9798 | Time elapsed: 16.72 min\n",
      "Epoch: 0018/0100 | Accuracy: 0.9803 | Val_accuracy: 0.9797 | Time elapsed: 17.63 min\n",
      "Epoch: 0019/0100 | Accuracy: 0.9819 | Val_accuracy: 0.9775 | Time elapsed: 18.57 min\n",
      "Epoch: 0020/0100 | Accuracy: 0.9812 | Val_accuracy: 0.9796 | Time elapsed: 19.51 min\n",
      "Test_accuracy: 0.9555\n",
      "Epoch: 0021/0100 | Accuracy: 0.9851 | Val_accuracy: 0.9857 | Time elapsed: 20.67 min\n",
      "Epoch: 0022/0100 | Accuracy: 0.9864 | Val_accuracy: 0.9868 | Time elapsed: 21.68 min\n",
      "Epoch: 0023/0100 | Accuracy: 0.9861 | Val_accuracy: 0.9859 | Time elapsed: 22.66 min\n",
      "Epoch: 0024/0100 | Accuracy: 0.9888 | Val_accuracy: 0.9832 | Time elapsed: 23.65 min\n",
      "Epoch: 0025/0100 | Accuracy: 0.9873 | Val_accuracy: 0.9908 | Time elapsed: 24.64 min\n",
      "Epoch: 0026/0100 | Accuracy: 0.9911 | Val_accuracy: 0.9908 | Time elapsed: 25.62 min\n",
      "Epoch: 0027/0100 | Accuracy: 0.9916 | Val_accuracy: 0.9923 | Time elapsed: 26.60 min\n",
      "Epoch: 0028/0100 | Accuracy: 0.9924 | Val_accuracy: 0.9920 | Time elapsed: 27.55 min\n",
      "Epoch: 0029/0100 | Accuracy: 0.9927 | Val_accuracy: 0.9929 | Time elapsed: 28.50 min\n",
      "Epoch: 0030/0100 | Accuracy: 0.9910 | Val_accuracy: 0.9920 | Time elapsed: 29.48 min\n",
      "Test_accuracy: 0.9543\n",
      "Epoch: 0031/0100 | Accuracy: 0.9935 | Val_accuracy: 0.9946 | Time elapsed: 30.60 min\n",
      "Epoch: 0032/0100 | Accuracy: 0.9939 | Val_accuracy: 0.9959 | Time elapsed: 31.58 min\n",
      "Epoch: 0033/0100 | Accuracy: 0.9945 | Val_accuracy: 0.9956 | Time elapsed: 32.56 min\n",
      "Epoch: 0034/0100 | Accuracy: 0.9959 | Val_accuracy: 0.9924 | Time elapsed: 33.49 min\n",
      "Epoch: 0035/0100 | Accuracy: 0.9946 | Val_accuracy: 0.9968 | Time elapsed: 34.42 min\n",
      "Epoch: 0036/0100 | Accuracy: 0.9965 | Val_accuracy: 0.9937 | Time elapsed: 35.37 min\n",
      "Epoch: 0037/0100 | Accuracy: 0.9950 | Val_accuracy: 0.9945 | Time elapsed: 36.35 min\n",
      "Epoch: 0038/0100 | Accuracy: 0.9967 | Val_accuracy: 0.9976 | Time elapsed: 37.29 min\n",
      "Epoch: 0039/0100 | Accuracy: 0.9975 | Val_accuracy: 0.9985 | Time elapsed: 38.25 min\n",
      "Epoch: 0040/0100 | Accuracy: 0.9971 | Val_accuracy: 0.9911 | Time elapsed: 39.21 min\n",
      "Test_accuracy: 0.9507\n",
      "Epoch: 0041/0100 | Accuracy: 0.9959 | Val_accuracy: 0.9980 | Time elapsed: 40.33 min\n",
      "Epoch: 0042/0100 | Accuracy: 0.9979 | Val_accuracy: 0.9988 | Time elapsed: 41.29 min\n",
      "Epoch: 0043/0100 | Accuracy: 0.9916 | Val_accuracy: 0.9968 | Time elapsed: 42.25 min\n",
      "Epoch: 0044/0100 | Accuracy: 0.9977 | Val_accuracy: 0.9982 | Time elapsed: 43.18 min\n",
      "Epoch: 0045/0100 | Accuracy: 0.9969 | Val_accuracy: 0.9982 | Time elapsed: 44.12 min\n",
      "Epoch: 0046/0100 | Accuracy: 0.9985 | Val_accuracy: 0.9990 | Time elapsed: 45.08 min\n",
      "Epoch: 0047/0100 | Accuracy: 0.9988 | Val_accuracy: 0.9992 | Time elapsed: 46.04 min\n",
      "Epoch: 0048/0100 | Accuracy: 0.9974 | Val_accuracy: 0.9988 | Time elapsed: 47.01 min\n",
      "Epoch: 0049/0100 | Accuracy: 0.9989 | Val_accuracy: 0.9987 | Time elapsed: 48.02 min\n",
      "Epoch: 0050/0100 | Accuracy: 0.9988 | Val_accuracy: 0.9994 | Time elapsed: 48.97 min\n",
      "Test_accuracy: 0.9508\n",
      "Epoch: 0051/0100 | Accuracy: 0.9991 | Val_accuracy: 0.9994 | Time elapsed: 50.06 min\n",
      "Epoch: 0052/0100 | Accuracy: 0.9987 | Val_accuracy: 0.9935 | Time elapsed: 51.02 min\n",
      "Epoch: 0053/0100 | Accuracy: 0.9959 | Val_accuracy: 0.9989 | Time elapsed: 52.01 min\n",
      "Epoch: 0054/0100 | Accuracy: 0.9990 | Val_accuracy: 0.9993 | Time elapsed: 52.96 min\n",
      "Epoch: 0055/0100 | Accuracy: 0.9992 | Val_accuracy: 0.9996 | Time elapsed: 53.92 min\n",
      "Epoch: 0056/0100 | Accuracy: 0.9994 | Val_accuracy: 0.9996 | Time elapsed: 54.88 min\n",
      "Epoch: 0057/0100 | Accuracy: 0.9990 | Val_accuracy: 0.9987 | Time elapsed: 55.83 min\n",
      "Epoch: 0058/0100 | Accuracy: 0.9987 | Val_accuracy: 0.9896 | Time elapsed: 56.78 min\n",
      "Epoch: 0059/0100 | Accuracy: 0.9959 | Val_accuracy: 0.9983 | Time elapsed: 57.72 min\n",
      "Epoch: 0060/0100 | Accuracy: 0.9991 | Val_accuracy: 0.9997 | Time elapsed: 58.73 min\n",
      "Test_accuracy: 0.9533\n",
      "Epoch: 0061/0100 | Accuracy: 0.9995 | Val_accuracy: 0.9997 | Time elapsed: 59.80 min\n",
      "Epoch: 0062/0100 | Accuracy: 0.9995 | Val_accuracy: 0.9996 | Time elapsed: 60.77 min\n",
      "Epoch: 0063/0100 | Accuracy: 0.9996 | Val_accuracy: 0.9997 | Time elapsed: 61.74 min\n",
      "Epoch: 0064/0100 | Accuracy: 0.9996 | Val_accuracy: 0.9997 | Time elapsed: 62.76 min\n",
      "Epoch: 0065/0100 | Accuracy: 0.9996 | Val_accuracy: 0.9999 | Time elapsed: 63.71 min\n",
      "Epoch: 0066/0100 | Accuracy: 0.9996 | Val_accuracy: 1.0000 | Time elapsed: 64.65 min\n",
      "Epoch: 0067/0100 | Accuracy: 0.9992 | Val_accuracy: 0.9966 | Time elapsed: 65.63 min\n",
      "Epoch: 0068/0100 | Accuracy: 0.9948 | Val_accuracy: 0.9986 | Time elapsed: 66.62 min\n",
      "Epoch: 0069/0100 | Accuracy: 0.9986 | Val_accuracy: 0.9972 | Time elapsed: 67.55 min\n",
      "Epoch: 0070/0100 | Accuracy: 0.9966 | Val_accuracy: 0.9999 | Time elapsed: 68.50 min\n",
      "Test_accuracy: 0.9528\n",
      "Epoch: 0071/0100 | Accuracy: 0.9989 | Val_accuracy: 0.9994 | Time elapsed: 69.66 min\n",
      "Epoch: 0072/0100 | Accuracy: 0.9995 | Val_accuracy: 0.9998 | Time elapsed: 70.67 min\n",
      "Epoch: 0073/0100 | Accuracy: 0.9996 | Val_accuracy: 1.0000 | Time elapsed: 71.63 min\n",
      "Epoch: 0074/0100 | Accuracy: 0.9990 | Val_accuracy: 0.9976 | Time elapsed: 72.61 min\n",
      "Epoch: 0075/0100 | Accuracy: 0.9958 | Val_accuracy: 0.9997 | Time elapsed: 73.57 min\n",
      "Epoch: 0076/0100 | Accuracy: 0.9995 | Val_accuracy: 0.9999 | Time elapsed: 74.55 min\n",
      "Epoch: 0077/0100 | Accuracy: 0.9997 | Val_accuracy: 1.0000 | Time elapsed: 75.55 min\n",
      "Epoch: 0078/0100 | Accuracy: 0.9997 | Val_accuracy: 1.0000 | Time elapsed: 76.57 min\n",
      "Epoch: 0079/0100 | Accuracy: 0.9997 | Val_accuracy: 1.0000 | Time elapsed: 77.53 min\n",
      "Epoch: 0080/0100 | Accuracy: 0.9997 | Val_accuracy: 1.0000 | Time elapsed: 78.48 min\n",
      "Test_accuracy: 0.9531\n",
      "Epoch: 0081/0100 | Accuracy: 0.9998 | Val_accuracy: 1.0000 | Time elapsed: 79.63 min\n",
      "Epoch: 0082/0100 | Accuracy: 0.9998 | Val_accuracy: 0.9999 | Time elapsed: 80.64 min\n",
      "Epoch: 0083/0100 | Accuracy: 0.9985 | Val_accuracy: 0.9996 | Time elapsed: 81.62 min\n",
      "Epoch: 0084/0100 | Accuracy: 0.9672 | Val_accuracy: 0.9765 | Time elapsed: 82.57 min\n",
      "Epoch: 0085/0100 | Accuracy: 0.9918 | Val_accuracy: 0.9970 | Time elapsed: 83.51 min\n",
      "Epoch: 0086/0100 | Accuracy: 0.9984 | Val_accuracy: 0.9993 | Time elapsed: 84.54 min\n",
      "Epoch: 0087/0100 | Accuracy: 0.9993 | Val_accuracy: 0.9997 | Time elapsed: 85.45 min\n",
      "Epoch: 0088/0100 | Accuracy: 0.9994 | Val_accuracy: 0.9999 | Time elapsed: 86.44 min\n",
      "Epoch: 0089/0100 | Accuracy: 0.9996 | Val_accuracy: 0.9999 | Time elapsed: 87.41 min\n",
      "Epoch: 0090/0100 | Accuracy: 0.9997 | Val_accuracy: 0.9999 | Time elapsed: 88.39 min\n",
      "Test_accuracy: 0.9536\n",
      "Epoch: 0091/0100 | Accuracy: 0.9997 | Val_accuracy: 0.9999 | Time elapsed: 89.47 min\n",
      "Epoch: 0092/0100 | Accuracy: 0.9997 | Val_accuracy: 0.9999 | Time elapsed: 90.48 min\n",
      "Epoch: 0093/0100 | Accuracy: 0.9997 | Val_accuracy: 0.9999 | Time elapsed: 91.55 min\n",
      "Epoch: 0094/0100 | Accuracy: 0.9997 | Val_accuracy: 1.0000 | Time elapsed: 92.59 min\n",
      "Epoch: 0095/0100 | Accuracy: 0.9998 | Val_accuracy: 1.0000 | Time elapsed: 93.59 min\n",
      "Epoch: 0096/0100 | Accuracy: 0.9998 | Val_accuracy: 1.0000 | Time elapsed: 94.59 min\n",
      "Epoch: 0097/0100 | Accuracy: 0.9998 | Val_accuracy: 1.0000 | Time elapsed: 95.60 min\n",
      "Epoch: 0098/0100 | Accuracy: 0.9996 | Val_accuracy: 0.9996 | Time elapsed: 96.57 min\n",
      "Epoch: 0099/0100 | Accuracy: 0.9757 | Val_accuracy: 0.9977 | Time elapsed: 97.59 min\n",
      "Epoch: 0100/0100 | Accuracy: 0.9976 | Val_accuracy: 0.9995 | Time elapsed: 98.55 min\n",
      "Test_accuracy: 0.9544\n",
      "Final Test_accuracy: 0.9544\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Training\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = train(valid_dl)\n",
    "    print(f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n",
    "          f'Accuracy: {acc_train:.4f} | '\n",
    "          f'Val_accuracy: {acc_valid:.4f} | '\n",
    "          f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    if (epoch+1)%10 == 0: # test every 10 epochs\n",
    "        # Test\n",
    "        acc_test, _ = evaluate(test_dl)\n",
    "        print(f'Test_accuracy: {acc_test:.4f}') \n",
    "# Test\n",
    "acc_test, _ = evaluate(test_dl)\n",
    "print(f'Final Test_accuracy: {acc_test:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional RNN\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size*2, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        _, (hidden, cell) = self.rnn(out)\n",
    "        out = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/0100 | Accuracy: 0.7963 | Val_accuracy: 0.8614 | Time elapsed: 1.11 min\n",
      "Epoch: 0002/0100 | Accuracy: 0.9084 | Val_accuracy: 0.9283 | Time elapsed: 2.17 min\n",
      "Epoch: 0003/0100 | Accuracy: 0.9398 | Val_accuracy: 0.9446 | Time elapsed: 3.36 min\n",
      "Epoch: 0004/0100 | Accuracy: 0.9525 | Val_accuracy: 0.9583 | Time elapsed: 4.47 min\n",
      "Epoch: 0005/0100 | Accuracy: 0.9613 | Val_accuracy: 0.9636 | Time elapsed: 5.61 min\n",
      "Epoch: 0006/0100 | Accuracy: 0.9666 | Val_accuracy: 0.9690 | Time elapsed: 6.69 min\n",
      "Epoch: 0007/0100 | Accuracy: 0.9712 | Val_accuracy: 0.9710 | Time elapsed: 7.78 min\n",
      "Epoch: 0008/0100 | Accuracy: 0.9749 | Val_accuracy: 0.9782 | Time elapsed: 8.86 min\n",
      "Epoch: 0009/0100 | Accuracy: 0.9800 | Val_accuracy: 0.9820 | Time elapsed: 9.96 min\n",
      "Epoch: 0010/0100 | Accuracy: 0.9823 | Val_accuracy: 0.9820 | Time elapsed: 11.10 min\n",
      "Test_accuracy: 0.9559\n",
      "Epoch: 0011/0100 | Accuracy: 0.9858 | Val_accuracy: 0.9868 | Time elapsed: 12.39 min\n",
      "Epoch: 0012/0100 | Accuracy: 0.9879 | Val_accuracy: 0.9892 | Time elapsed: 13.55 min\n",
      "Epoch: 0013/0100 | Accuracy: 0.9901 | Val_accuracy: 0.9929 | Time elapsed: 14.71 min\n",
      "Epoch: 0014/0100 | Accuracy: 0.9923 | Val_accuracy: 0.9937 | Time elapsed: 15.82 min\n",
      "Epoch: 0015/0100 | Accuracy: 0.9937 | Val_accuracy: 0.9928 | Time elapsed: 16.95 min\n",
      "Epoch: 0016/0100 | Accuracy: 0.9941 | Val_accuracy: 0.9956 | Time elapsed: 18.11 min\n",
      "Epoch: 0017/0100 | Accuracy: 0.9875 | Val_accuracy: 0.9926 | Time elapsed: 19.25 min\n",
      "Epoch: 0018/0100 | Accuracy: 0.9958 | Val_accuracy: 0.9972 | Time elapsed: 20.35 min\n",
      "Epoch: 0019/0100 | Accuracy: 0.9978 | Val_accuracy: 0.9977 | Time elapsed: 21.48 min\n",
      "Epoch: 0020/0100 | Accuracy: 0.9982 | Val_accuracy: 0.9993 | Time elapsed: 22.63 min\n",
      "Test_accuracy: 0.9557\n",
      "Epoch: 0021/0100 | Accuracy: 0.9965 | Val_accuracy: 0.9978 | Time elapsed: 23.95 min\n",
      "Epoch: 0022/0100 | Accuracy: 0.9955 | Val_accuracy: 0.9975 | Time elapsed: 25.07 min\n",
      "Epoch: 0023/0100 | Accuracy: 0.9984 | Val_accuracy: 0.9990 | Time elapsed: 26.24 min\n",
      "Epoch: 0024/0100 | Accuracy: 0.9993 | Val_accuracy: 0.9998 | Time elapsed: 27.38 min\n",
      "Epoch: 0025/0100 | Accuracy: 0.9981 | Val_accuracy: 0.9966 | Time elapsed: 28.56 min\n",
      "Epoch: 0026/0100 | Accuracy: 0.9986 | Val_accuracy: 0.9988 | Time elapsed: 29.68 min\n",
      "Epoch: 0027/0100 | Accuracy: 0.9986 | Val_accuracy: 0.9997 | Time elapsed: 30.83 min\n",
      "Epoch: 0028/0100 | Accuracy: 0.9990 | Val_accuracy: 0.9977 | Time elapsed: 31.95 min\n",
      "Epoch: 0029/0100 | Accuracy: 0.9962 | Val_accuracy: 0.9990 | Time elapsed: 33.03 min\n",
      "Epoch: 0030/0100 | Accuracy: 0.9991 | Val_accuracy: 0.9998 | Time elapsed: 34.19 min\n",
      "Test_accuracy: 0.9563\n",
      "Epoch: 0031/0100 | Accuracy: 0.9993 | Val_accuracy: 0.9894 | Time elapsed: 35.52 min\n",
      "Epoch: 0032/0100 | Accuracy: 0.9968 | Val_accuracy: 0.9993 | Time elapsed: 36.62 min\n",
      "Epoch: 0033/0100 | Accuracy: 0.9999 | Val_accuracy: 1.0000 | Time elapsed: 37.79 min\n",
      "Epoch: 0034/0100 | Accuracy: 0.9999 | Val_accuracy: 0.9999 | Time elapsed: 38.92 min\n",
      "Epoch: 0035/0100 | Accuracy: 0.9975 | Val_accuracy: 0.9976 | Time elapsed: 40.02 min\n",
      "Epoch: 0036/0100 | Accuracy: 0.9993 | Val_accuracy: 1.0000 | Time elapsed: 41.10 min\n",
      "Epoch: 0037/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 42.22 min\n",
      "Epoch: 0038/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 43.32 min\n",
      "Epoch: 0039/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 44.40 min\n",
      "Epoch: 0040/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 45.48 min\n",
      "Test_accuracy: 0.9577\n",
      "Epoch: 0041/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 46.73 min\n",
      "Epoch: 0042/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 47.81 min\n",
      "Epoch: 0043/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 48.88 min\n",
      "Epoch: 0044/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 49.96 min\n",
      "Epoch: 0045/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 51.01 min\n",
      "Epoch: 0046/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 52.11 min\n",
      "Epoch: 0047/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 53.20 min\n",
      "Epoch: 0048/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 54.26 min\n",
      "Epoch: 0049/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 55.34 min\n",
      "Epoch: 0050/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 56.43 min\n",
      "Test_accuracy: 0.9581\n",
      "Epoch: 0051/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 57.68 min\n",
      "Epoch: 0052/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 58.77 min\n",
      "Epoch: 0053/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 59.84 min\n",
      "Epoch: 0054/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 60.92 min\n",
      "Epoch: 0055/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 61.97 min\n",
      "Epoch: 0056/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 63.06 min\n",
      "Epoch: 0057/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 64.17 min\n",
      "Epoch: 0058/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 65.32 min\n",
      "Epoch: 0059/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 66.46 min\n",
      "Epoch: 0060/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 67.54 min\n",
      "Test_accuracy: 0.9579\n",
      "Epoch: 0061/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 68.77 min\n",
      "Epoch: 0062/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 69.84 min\n",
      "Epoch: 0063/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 70.95 min\n",
      "Epoch: 0064/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 72.05 min\n",
      "Epoch: 0065/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 73.15 min\n",
      "Epoch: 0066/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 74.27 min\n",
      "Epoch: 0067/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 75.42 min\n",
      "Epoch: 0068/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 76.48 min\n",
      "Epoch: 0069/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 77.59 min\n",
      "Epoch: 0070/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 78.69 min\n",
      "Test_accuracy: 0.9577\n",
      "Epoch: 0071/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 79.93 min\n",
      "Epoch: 0072/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 81.04 min\n",
      "Epoch: 0073/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 82.15 min\n",
      "Epoch: 0074/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 83.22 min\n",
      "Epoch: 0075/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 84.29 min\n",
      "Epoch: 0076/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 85.42 min\n",
      "Epoch: 0077/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 86.52 min\n",
      "Epoch: 0078/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 87.59 min\n",
      "Epoch: 0079/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 88.71 min\n",
      "Epoch: 0080/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 89.86 min\n",
      "Test_accuracy: 0.9578\n",
      "Epoch: 0081/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 91.19 min\n",
      "Epoch: 0082/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 92.33 min\n",
      "Epoch: 0083/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 93.42 min\n",
      "Epoch: 0084/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 94.58 min\n",
      "Epoch: 0085/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 95.73 min\n",
      "Epoch: 0086/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 96.85 min\n",
      "Epoch: 0087/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 97.94 min\n",
      "Epoch: 0088/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 99.00 min\n",
      "Epoch: 0089/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 100.12 min\n",
      "Epoch: 0090/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 101.33 min\n",
      "Test_accuracy: 0.9578\n",
      "Epoch: 0091/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 102.63 min\n",
      "Epoch: 0092/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 103.71 min\n",
      "Epoch: 0093/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 104.81 min\n",
      "Epoch: 0094/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 105.87 min\n",
      "Epoch: 0095/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 106.96 min\n",
      "Epoch: 0096/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 108.03 min\n",
      "Epoch: 0097/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 109.10 min\n",
      "Epoch: 0098/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 110.18 min\n",
      "Epoch: 0099/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 111.30 min\n",
      "Epoch: 0100/0100 | Accuracy: 1.0000 | Val_accuracy: 1.0000 | Time elapsed: 112.42 min\n",
      "Test_accuracy: 0.9577\n",
      "Final Test_accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model = model.to(DEVICE)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Training\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = train(valid_dl)\n",
    "    print(f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n",
    "          f'Accuracy: {acc_train:.4f} | '\n",
    "          f'Val_accuracy: {acc_valid:.4f} | '\n",
    "          f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    if (epoch+1)%10 == 0: # test every 10 epochs\n",
    "        # Test\n",
    "        acc_test, _ = evaluate(test_dl)\n",
    "        print(f'Test_accuracy: {acc_test:.4f}') \n",
    "# Test\n",
    "acc_test, _ = evaluate(test_dl)\n",
    "print(f'Final Test_accuracy: {acc_test:.4f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
